{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePgXAR0b4A5f"
   },
   "source": [
    "# Software Defect Prediction using SMOTE based Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlL1Jcmq5oek"
   },
   "source": [
    "## Reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hbDyluw15oK8",
    "outputId": "f6716840-197b-4746-d2ef-19971d384373"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "def repro():\n",
    "  # Seed value\n",
    "  # Apparently you may use different seed values at each stage\n",
    "  seed_value= 42\n",
    "\n",
    "  # 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "  import os\n",
    "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "  # 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "  import random\n",
    "  random.seed(seed_value)\n",
    "\n",
    "  # 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "  import numpy as np\n",
    "  np.random.seed(seed_value)\n",
    "\n",
    "  # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "  import tensorflow as tf\n",
    "  tf.random.set_seed(seed_value)\n",
    "  # for later versions: \n",
    "  # tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "  # 5. Configure a new global `tensorflow` session\n",
    "  from keras import backend as K\n",
    "  # session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "  # sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "  # K.set_session(sess)\n",
    "  # for later versions:\n",
    "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "  sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "  tf.compat.v1.keras.backend.set_session(sess)\n",
    "repro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWMbR2s__Y1F"
   },
   "outputs": [],
   "source": [
    "repro()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xyYtsD1d4tnW"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "j-Y5r-lV4Aa1",
    "outputId": "6ab1266c-b118-4510-dc9e-1629932a9420"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix    #Confussion Matrix\n",
    "from sklearn import metrics                     #Evaluation Measurment\\\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.models import Sequential       \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras\n",
    "# from tensorflow.keras import optimizers\n",
    "\n",
    "import math\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "import matplotlib.pyplot as plt                 #Visualisasi\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "modelrf=RandomForestClassifier(random_state=42)\n",
    "modelnb = GaussianNB()\n",
    "modellogreg = LogisticRegression()\n",
    "modeldt = DecisionTreeClassifier()\n",
    "modelsvm = SVC()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whrZA7Vv4vds"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 713
    },
    "colab_type": "code",
    "id": "LdURQKPa4omK",
    "outputId": "a06c2c79-7c82-4bdd-b57d-cdc5988f0860",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Data</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CM1</td>\n",
       "      <td>498</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JM1</td>\n",
       "      <td>10880</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MW1</td>\n",
       "      <td>253</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KC1</td>\n",
       "      <td>2109</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KC2</td>\n",
       "      <td>522</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PC1</td>\n",
       "      <td>1109</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PC2</td>\n",
       "      <td>745</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PC3</td>\n",
       "      <td>1077</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PC4</td>\n",
       "      <td>1458</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset   Data  Feature\n",
       "0     CM1    498       22\n",
       "1     JM1  10880       22\n",
       "2     MW1    253       38\n",
       "3     KC1   2109       22\n",
       "4     KC2    522       22\n",
       "5     PC1   1109       22\n",
       "6     PC2    745       37\n",
       "7     PC3   1077       38\n",
       "8     PC4   1458       38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "repro()\n",
    "#Import CM1 Dataset\n",
    "data_cm1 = pd.read_csv('Dataset/clean/CM1.csv')\n",
    "\n",
    "#import + Preprocess JM1 Dataset\n",
    "data_jm1 = pd.read_csv('Dataset/clean/JM1.csv')\n",
    "indexNames = data_jm1[ data_jm1['branchCount'] == '?' ].index\n",
    "data_jm1.drop(indexNames , inplace=True)\n",
    "\n",
    "#import MW1 Dataset\n",
    "data_mw1 = pd.read_csv('Dataset/clean/MW1.csv')\n",
    "\n",
    "#import KC1 Dataset\n",
    "data_kc1 = pd.read_csv('Dataset/clean/KC1.csv')\n",
    "\n",
    "#import KC2 Dataset ------------------\n",
    "data_kc2 = pd.read_csv('Dataset/clean/KC2.csv')\n",
    "\n",
    "#import PC1 Dataset\n",
    "data_pc1 = pd.read_csv('Dataset/clean/PC1.csv')\n",
    "\n",
    "#import PC2 Dataset -------------\n",
    "data_pc2 = pd.read_csv('Dataset/clean/PC2.csv')\n",
    "\n",
    "#import PC3 Dataset ----------------\n",
    "data_pc3 = pd.read_csv('Dataset/clean/PC3.csv')\n",
    "\n",
    "#import PC4 Dataset\n",
    "data_pc4 = pd.read_csv('Dataset/clean/PC4.csv')\n",
    "\n",
    "\n",
    "#Visualisasi Jumlah Data\n",
    "names = ['CM1', 'JM1', 'MW1', 'KC1', 'KC2', 'PC1', 'PC2', 'PC3', 'PC4']\n",
    "values_data = [data_cm1.shape[0], data_jm1.shape[0], data_mw1.shape[0],data_kc1.shape[0],data_kc2.shape[0],\n",
    "          data_pc1.shape[0],data_pc2.shape[0],data_pc3.shape[0],data_pc4.shape[0]]\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.bar(names, values_data)\n",
    "\n",
    "#Visualisasi Jumlah Fitur\n",
    "values_feature = [data_cm1.shape[1], data_jm1.shape[1], data_mw1.shape[1],data_kc1.shape[1],data_kc2.shape[1],\n",
    "          data_pc1.shape[1],data_pc2.shape[1],data_pc3.shape[1],data_pc4.shape[1]]\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.bar(names, values_feature)\n",
    "\n",
    "# data_pc4.iloc[:, data_pc4.columns != 'c'] = scaler.fit_transform(data_pc4.iloc[:, data_pc4.columns != 'c'])\n",
    "# data_pc3.iloc[:, data_pc3.columns != 'Defective'] = scaler.fit_transform(data_pc3.iloc[:, data_pc3.columns != 'Defective'])\n",
    "\n",
    "Dataset = {'Dataset': ['CM1', 'JM1', 'MW1', 'KC1', 'KC2', 'PC1', 'PC2', 'PC3', 'PC4'],\n",
    "           'Data': [data_cm1.shape[0], data_jm1.shape[0], data_mw1.shape[0],data_kc1.shape[0],data_kc2.shape[0],\n",
    "                    data_pc1.shape[0],data_pc2.shape[0],data_pc3.shape[0],data_pc4.shape[0]],\n",
    "           'Feature': [data_cm1.shape[1], data_jm1.shape[1], data_mw1.shape[1],data_kc1.shape[1],data_kc2.shape[1],\n",
    "                       data_pc1.shape[1],data_pc2.shape[1],data_pc3.shape[1],data_pc4.shape[1]]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(Dataset, columns = ['Dataset', 'Data','Feature'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rLUfG0hJ53gF"
   },
   "source": [
    "## Min-Max Scaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbpfgILH55Zl"
   },
   "outputs": [],
   "source": [
    "repro()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data_cm1.iloc[:, data_cm1.columns != 'class'] = scaler.fit_transform(data_cm1.iloc[:, data_cm1.columns != 'class'])\n",
    "data_jm1.iloc[:, data_jm1.columns != 'defects'] = scaler.fit_transform(data_jm1.iloc[:, data_jm1.columns != 'defects'])\n",
    "data_kc1.iloc[:, data_kc1.columns != 'class'] = scaler.fit_transform(data_kc1.iloc[:, data_kc1.columns != 'class'])\n",
    "data_kc2.iloc[:, data_kc2.columns != 'class'] = scaler.fit_transform(data_kc2.iloc[:, data_kc2.columns != 'class'])\n",
    "data_pc1.iloc[:, data_pc1.columns != 'class'] = scaler.fit_transform(data_pc1.iloc[:, data_pc1.columns != 'class'])\n",
    "data_pc2.iloc[:, data_pc2.columns != 'Defective'] = scaler.fit_transform(data_pc2.iloc[:, data_pc2.columns != 'Defective'])\n",
    "data_pc3.iloc[:, data_pc3.columns != 'Defective'] = scaler.fit_transform(data_pc3.iloc[:, data_pc3.columns != 'Defective'])\n",
    "data_pc4.iloc[:, data_pc4.columns != 'c'] = scaler.fit_transform(data_pc4.iloc[:, data_pc4.columns != 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zY9VZ3j-U2aU"
   },
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQSzSW9fU4hk"
   },
   "outputs": [],
   "source": [
    "def bal(y_true, Y_pred):\n",
    "    repro()\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, Y_pred, labels=[0,1]).ravel()\n",
    "    pf = fp/(fp+tn)\n",
    "    bal = 1 - ((math.sqrt((1-recall(y_true, Y_pred))**2+ pf**2))/(math.sqrt(2)))\n",
    "    return bal\n",
    "\n",
    "def auc(y_true, Y_pred):\n",
    "    repro()\n",
    "    # fpr, tpr, thresholds = metrics.roc_curve(y_test, Y_pred, pos_label=True)\n",
    "    auc = metrics.roc_auc_score(y_true, Y_pred)\n",
    "    return auc\n",
    "\n",
    "def gmeans(y_true, Y_pred):\n",
    "    # repro()\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, Y_pred, labels=[0,1]).ravel()\n",
    "    pf = fp/(fp+tn)\n",
    "    pd = tp/(tp+fn)\n",
    "    gmeans = math.sqrt(pd*(1-pf))\n",
    "    return gmeans\n",
    "\n",
    "def pf(y_true, Y_pred):\n",
    "    repro()\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, Y_pred, labels=[0,1]).ravel()\n",
    "    # print(tn)\n",
    "    pf = fp/(fp+tn)\n",
    "    return pf\n",
    "\n",
    "def recall(y_true, Y_pred):\n",
    "  repro()\n",
    "  tn, fp, fn, tp = confusion_matrix(y_true, Y_pred, labels=[0,1]).ravel()\n",
    "  pd = tp/(tp+fn)\n",
    "  return pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3iW8qkdw6ssD"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_DT(data, \n",
    "              y_name, \n",
    "              fold,\n",
    "              smote = True):\n",
    "\n",
    "  X = data.iloc[:, data.columns != y_name ]\n",
    "  y = data[y_name]\n",
    "\n",
    "  kfold_inner = StratifiedKFold(n_splits=fold, shuffle=True, random_state=42)\n",
    "  kfold_outer = StratifiedKFold(n_splits=fold, shuffle=True, random_state=42)\n",
    "  sm = SMOTE(random_state=42)\n",
    "\n",
    "  model = KNeighborsClassifier()\n",
    "    \n",
    "#, max_depth=depth, n_estimators=estimator\n",
    "  scoring = {'recall': metrics.make_scorer(recall), \n",
    "             'bal': metrics.make_scorer(bal), \n",
    "             'auc':metrics.make_scorer(metrics.roc_auc_score), \n",
    "             'gmeans':metrics.make_scorer(gmeans)}\n",
    "\n",
    "  \n",
    "  if (smote == True):\n",
    "    pipeline = Pipeline([('sm', sm), ('clf', model)])\n",
    "    distributions = dict(clf__leaf_size = [ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 100],\n",
    "                         clf__n_neighbors = [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
    "                         sm__k_neighbors = [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
    "                         sm__sampling_strategy = [0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9 ,\n",
    "                                                  0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99])\n",
    "#   else:\n",
    "#     pipeline = Pipeline([('clf', model)])\n",
    "#     distributions = dict(clf__max_depth = np.arange(5,10,1))\n",
    "    \n",
    "  clf = RandomizedSearchCV(pipeline, distributions, random_state=42, cv=kfold_inner, scoring = scoring, refit = 'bal', n_jobs = -1, n_iter=50, verbose = 1)\n",
    "  result = cross_validate(clf, X=X, y=y, cv=kfold_outer, scoring=scoring)\n",
    "  print('bal: ', result['test_bal'].mean())\n",
    "  print('recall: ', result['test_recall'].mean())\n",
    "  print('auc: ', result['test_auc'].mean())\n",
    "  print('gmeans: ', result['test_gmeans'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pvF5VQkh62qy"
   },
   "source": [
    "### KC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   54.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   53.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   57.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   59.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bal:  0.7075084373908205\n",
      "recall:  0.7238228438228439\n",
      "auc:  0.7110419730082652\n",
      "gmeans:  0.7097582531263477\n"
     ]
    }
   ],
   "source": [
    "repro()\n",
    "search_rf_kc1 = search_DT(data_kc1, 'class', 5, smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NDTBS4PD65PC"
   },
   "source": [
    "### KC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   56.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   57.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   55.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   52.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   49.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bal:  0.7568941854460896\n",
      "recall:  0.7471861471861472\n",
      "auc:  0.766364157930423\n",
      "gmeans:  0.7622432689566717\n"
     ]
    }
   ],
   "source": [
    "repro()\n",
    "search_kc2 = search_DT(data_kc2, 'class', 5, smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   51.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   54.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   59.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bal:  0.7736206371976065\n",
      "recall:  0.7925\n",
      "auc:  0.7794871839969983\n",
      "gmeans:  0.7778489787011824\n"
     ]
    }
   ],
   "source": [
    "repro()\n",
    "search_pc1 = search_DT(data_pc1, 'class', 5, smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bal:  0.7324845009703858\n",
      "recall:  0.7227920227920228\n",
      "auc:  0.7352308644861836\n",
      "gmeans:  0.7339019054667718\n"
     ]
    }
   ],
   "source": [
    "repro()\n",
    "search_pc3 = search_DT(data_pc3, 'Defective', 5, smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PC4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bal:  0.7810912967921397\n",
      "recall:  0.7923809523809524\n",
      "auc:  0.7848623511904762\n",
      "gmeans:  0.7837881576114641\n"
     ]
    }
   ],
   "source": [
    "\n",
    "repro()\n",
    "search_pc4 = search_DT(data_pc4, 'c', 5, smote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bal:  0.6511349355186618\n",
      "recall:  0.6352901255514081\n",
      "auc:  0.6532389078911892\n",
      "gmeans:  0.6520832901187115\n"
     ]
    }
   ],
   "source": [
    "repro()\n",
    "search_jm1 = search_DT(data_jm1, 'defects', 5, smote=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SMOTE_NN_IEEE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
